{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trigger words.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVNNnRDTqpSN"
      },
      "source": [
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"accelerator\": \"GPU\",\n",
        "    \"colab\": {\n",
        "      \"name\": \"SM2_project.ipynb\",\n",
        "      \"provenance\": [],\n",
        "      \"private_outputs\": true,\n",
        "      \"collapsed_sections\": [],\n",
        "      \"toc_visible\": true\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"display_name\": \"Python 3\",\n",
        "      \"name\": \"python3\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"dzLKpmZICaWN\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"import os\\n\",\n",
        "        \"import pathlib\\n\",\n",
        "        \"\\n\",\n",
        "        \"import matplotlib.pyplot as plt\\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"import seaborn as sns\\n\",\n",
        "        \"import tensorflow as tf\\n\",\n",
        "        \"\\n\",\n",
        "        \"from tensorflow.keras.layers.experimental import preprocessing\\n\",\n",
        "        \"from tensorflow.keras import layers\\n\",\n",
        "        \"from tensorflow.keras import models\\n\",\n",
        "        \"from IPython import display\\n\",\n",
        "        \"\\n\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"2-rayb7-3Y0I\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"data_dir = pathlib.Path('data/mini_speech_commands')\\n\",\n",
        "        \"if not data_dir.exists():\\n\",\n",
        "        \"  tf.keras.utils.get_file(\\n\",\n",
        "        \"      'mini_speech_commands.zip',\\n\",\n",
        "        \"      origin=\\\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\\\",\\n\",\n",
        "        \"      extract=True,\\n\",\n",
        "        \"      cache_dir='.', cache_subdir='data')\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"70IBxSKxA1N9\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"commands = np.array(tf.io.gfile.listdir(str(data_dir)))\\n\",\n",
        "        \"commands = commands[commands != 'README.md']\\n\",\n",
        "        \"print('Commands:', commands)\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"hlX685l1wD9k\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\\n\",\n",
        "        \"filenames = tf.random.shuffle(filenames)\\n\",\n",
        "        \"num_samples = len(filenames)\\n\",\n",
        "        \"print('Number of total examples:', num_samples)\\n\",\n",
        "        \"print('Number of examples per label:',\\n\",\n",
        "        \"      len(tf.io.gfile.listdir(str(data_dir/commands[0]))))\\n\",\n",
        "        \"print('Example file tensor:', filenames[0])\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"Cv_wts-l3KgD\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"train_files = filenames[:6400]\\n\",\n",
        "        \"val_files = filenames[6400: 6400 + 800]\\n\",\n",
        "        \"test_files = filenames[-800:]\\n\",\n",
        "        \"\\n\",\n",
        "        \"print('Training set size', len(train_files))\\n\",\n",
        "        \"print('Validation set size', len(val_files))\\n\",\n",
        "        \"print('Test set size', len(test_files))\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"9PjJ2iXYwftD\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"def decode_audio(audio_binary):\\n\",\n",
        "        \"  audio, _ = tf.audio.decode_wav(audio_binary)\\n\",\n",
        "        \"  return tf.squeeze(audio, axis=-1)\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"8VTtX1nr3YT-\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"def get_label(file_path):\\n\",\n",
        "        \"  parts = tf.strings.split(file_path, os.path.sep)\\n\",\n",
        "        \"\\n\",\n",
        "        \"  # Note: You'll use indexing here instead of tuple unpacking to enable this \\n\",\n",
        "        \"  # to work in a TensorFlow graph.\\n\",\n",
        "        \"  return parts[-2] \"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"WdgUD5T93NyT\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"def get_waveform_and_label(file_path):\\n\",\n",
        "        \"  label = get_label(file_path)\\n\",\n",
        "        \"  audio_binary = tf.io.read_file(file_path)\\n\",\n",
        "        \"  waveform = decode_audio(audio_binary)\\n\",\n",
        "        \"  return waveform, label\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"0SQl8yXl3kNP\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"AUTOTUNE = tf.data.experimental.AUTOTUNE\\n\",\n",
        "        \"files_ds = tf.data.Dataset.from_tensor_slices(train_files)\\n\",\n",
        "        \"waveform_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"8yuX6Nqzf6wT\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"rows = 3\\n\",\n",
        "        \"cols = 3\\n\",\n",
        "        \"n = rows*cols\\n\",\n",
        "        \"fig, axes = plt.subplots(rows, cols, figsize=(10, 12))\\n\",\n",
        "        \"for i, (audio, label) in enumerate(waveform_ds.take(n)):\\n\",\n",
        "        \"  r = i // cols\\n\",\n",
        "        \"  c = i % cols\\n\",\n",
        "        \"  ax = axes[r][c]\\n\",\n",
        "        \"  ax.plot(audio.numpy())\\n\",\n",
        "        \"  ax.set_yticks(np.arange(-1.2, 1.2, 0.2))\\n\",\n",
        "        \"  label = label.numpy().decode('utf-8')\\n\",\n",
        "        \"  ax.set_title(label)\\n\",\n",
        "        \"\\n\",\n",
        "        \"plt.show()\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"_4CK75DHz_OR\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"def get_spectrogram(waveform):\\n\",\n",
        "        \"  # Padding for files with less than 16000 samples\\n\",\n",
        "        \"  zero_padding = tf.zeros([16000] - tf.shape(waveform), dtype=tf.float32)\\n\",\n",
        "        \"\\n\",\n",
        "        \"  # Concatenate audio with padding so that all audio clips will be of the \\n\",\n",
        "        \"  # same length\\n\",\n",
        "        \"  waveform = tf.cast(waveform, tf.float32)\\n\",\n",
        "        \"  equal_length = tf.concat([waveform, zero_padding], 0)\\n\",\n",
        "        \"  spectrogram = tf.signal.stft(\\n\",\n",
        "        \"      equal_length, frame_length=255, frame_step=128)\\n\",\n",
        "        \"      \\n\",\n",
        "        \"  spectrogram = tf.abs(spectrogram)\\n\",\n",
        "        \"\\n\",\n",
        "        \"  return spectrogram\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"4Mu6Y7Yz3C-V\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"for waveform, label in waveform_ds.take(1):\\n\",\n",
        "        \"  label = label.numpy().decode('utf-8')\\n\",\n",
        "        \"  spectrogram = get_spectrogram(waveform)\\n\",\n",
        "        \"\\n\",\n",
        "        \"print('Label:', label)\\n\",\n",
        "        \"print('Waveform shape:', waveform.shape)\\n\",\n",
        "        \"print('Spectrogram shape:', spectrogram.shape)\\n\",\n",
        "        \"print('Audio playback')\\n\",\n",
        "        \"display.display(display.Audio(waveform, rate=16000))\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"e62jzb36-Jog\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"def plot_spectrogram(spectrogram, ax):\\n\",\n",
        "        \"  # Convert to frequencies to log scale and transpose so that the time is\\n\",\n",
        "        \"  # represented in the x-axis (columns).\\n\",\n",
        "        \"  log_spec = np.log(spectrogram.T)\\n\",\n",
        "        \"  height = log_spec.shape[0]\\n\",\n",
        "        \"  X = np.arange(16000, step=height + 1)\\n\",\n",
        "        \"  Y = range(height)\\n\",\n",
        "        \"  ax.pcolormesh(X, Y, log_spec)\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"fig, axes = plt.subplots(2, figsize=(12, 8))\\n\",\n",
        "        \"timescale = np.arange(waveform.shape[0])\\n\",\n",
        "        \"axes[0].plot(timescale, waveform.numpy())\\n\",\n",
        "        \"axes[0].set_title('Waveform')\\n\",\n",
        "        \"axes[0].set_xlim([0, 16000])\\n\",\n",
        "        \"plot_spectrogram(spectrogram.numpy(), axes[1])\\n\",\n",
        "        \"axes[1].set_title('Spectrogram')\\n\",\n",
        "        \"plt.show()\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"43IS2IouEV40\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"def get_spectrogram_and_label_id(audio, label):\\n\",\n",
        "        \"  spectrogram = get_spectrogram(audio)\\n\",\n",
        "        \"  spectrogram = tf.expand_dims(spectrogram, -1)\\n\",\n",
        "        \"  label_id = tf.argmax(label == commands)\\n\",\n",
        "        \"  return spectrogram, label_id\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"yEVb_oK0oBLQ\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"spectrogram_ds = waveform_ds.map(\\n\",\n",
        "        \"    get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"QUbHfTuon4iF\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"rows = 3\\n\",\n",
        "        \"cols = 3\\n\",\n",
        "        \"n = rows*cols\\n\",\n",
        "        \"fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\\n\",\n",
        "        \"for i, (spectrogram, label_id) in enumerate(spectrogram_ds.take(n)):\\n\",\n",
        "        \"  r = i // cols\\n\",\n",
        "        \"  c = i % cols\\n\",\n",
        "        \"  ax = axes[r][c]\\n\",\n",
        "        \"  plot_spectrogram(np.squeeze(spectrogram.numpy()), ax)\\n\",\n",
        "        \"  ax.set_title(commands[label_id.numpy()])\\n\",\n",
        "        \"  ax.axis('off')\\n\",\n",
        "        \"  \\n\",\n",
        "        \"plt.show()\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"10UI32QH_45b\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"def preprocess_dataset(files):\\n\",\n",
        "        \"  files_ds = tf.data.Dataset.from_tensor_slices(files)\\n\",\n",
        "        \"  output_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\\n\",\n",
        "        \"  output_ds = output_ds.map(\\n\",\n",
        "        \"      get_spectrogram_and_label_id,  num_parallel_calls=AUTOTUNE)\\n\",\n",
        "        \"  return output_ds\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"HNv4xwYkB2P6\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"train_ds = spectrogram_ds\\n\",\n",
        "        \"val_ds = preprocess_dataset(val_files)\\n\",\n",
        "        \"test_ds = preprocess_dataset(test_files)\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"UgY9WYzn61EX\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"batch_size = 64\\n\",\n",
        "        \"train_ds = train_ds.batch(batch_size)\\n\",\n",
        "        \"val_ds = val_ds.batch(batch_size)\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"fdZ6M-F5_QzY\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"train_ds = train_ds.cache().prefetch(AUTOTUNE)\\n\",\n",
        "        \"val_ds = val_ds.cache().prefetch(AUTOTUNE)\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"ALYz7PFCHblP\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"for spectrogram, _ in spectrogram_ds.take(1):\\n\",\n",
        "        \"  input_shape = spectrogram.shape\\n\",\n",
        "        \"print('Input shape:', input_shape)\\n\",\n",
        "        \"num_labels = len(commands)\\n\",\n",
        "        \"\\n\",\n",
        "        \"norm_layer = preprocessing.Normalization()\\n\",\n",
        "        \"norm_layer.adapt(spectrogram_ds.map(lambda x, _: x))\\n\",\n",
        "        \"\\n\",\n",
        "        \"model = models.Sequential([\\n\",\n",
        "        \"    layers.Input(shape=input_shape),\\n\",\n",
        "        \"    preprocessing.Resizing(32, 32), \\n\",\n",
        "        \"    norm_layer,\\n\",\n",
        "        \"    layers.Conv2D(32, 3, activation='relu'),\\n\",\n",
        "        \"    layers.Conv2D(64, 3, activation='relu'),\\n\",\n",
        "        \"    layers.MaxPooling2D(),\\n\",\n",
        "        \"    layers.Dropout(0.25),\\n\",\n",
        "        \"    layers.Flatten(),\\n\",\n",
        "        \"    layers.Dense(128, activation='relu'),\\n\",\n",
        "        \"    layers.Dropout(0.5),\\n\",\n",
        "        \"    layers.Dense(num_labels),\\n\",\n",
        "        \"])\\n\",\n",
        "        \"\\n\",\n",
        "        \"model.summary()\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"poJfoXyEbVGe\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"spectrogram_ds.map(lambda x, _: x)\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"wFjj7-EmsTD-\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"model.compile(\\n\",\n",
        "        \"    optimizer=tf.keras.optimizers.Adam(),\\n\",\n",
        "        \"    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\\n\",\n",
        "        \"    metrics=['accuracy'],\\n\",\n",
        "        \")\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"ttioPJVMcGtq\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"EPOCHS = 10\\n\",\n",
        "        \"history = model.fit(\\n\",\n",
        "        \"    train_ds, \\n\",\n",
        "        \"    validation_data=val_ds,  \\n\",\n",
        "        \"    epochs=EPOCHS,\\n\",\n",
        "        \"    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\\n\",\n",
        "        \")\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"nzhipg3Gu2AY\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"metrics = history.history\\n\",\n",
        "        \"plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\\n\",\n",
        "        \"plt.legend(['loss', 'val_loss'])\\n\",\n",
        "        \"plt.show()\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"biU2MwzyAo8o\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"test_audio = []\\n\",\n",
        "        \"test_labels = []\\n\",\n",
        "        \"\\n\",\n",
        "        \"for audio, label in test_ds:\\n\",\n",
        "        \"  test_audio.append(audio.numpy())\\n\",\n",
        "        \"  test_labels.append(label.numpy())\\n\",\n",
        "        \"\\n\",\n",
        "        \"test_audio = np.array(test_audio)\\n\",\n",
        "        \"test_labels = np.array(test_labels)\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"ktUanr9mRZky\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"y_pred = np.argmax(model.predict(test_audio), axis=1)\\n\",\n",
        "        \"y_true = test_labels\\n\",\n",
        "        \"\\n\",\n",
        "        \"test_acc = sum(y_pred == y_true) / len(y_true)\\n\",\n",
        "        \"print(f'Test set accuracy: {test_acc:.0%}')\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"LvoSAOiXU3lL\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"confusion_mtx = tf.math.confusion_matrix(y_true, y_pred) \\n\",\n",
        "        \"plt.figure(figsize=(10, 8))\\n\",\n",
        "        \"sns.heatmap(confusion_mtx, xticklabels=commands, yticklabels=commands, \\n\",\n",
        "        \"            annot=True, fmt='g')\\n\",\n",
        "        \"plt.xlabel('Prediction')\\n\",\n",
        "        \"plt.ylabel('Label')\\n\",\n",
        "        \"plt.show()\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"zRxauKMdhofU\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"sample_file = data_dir/'no/01bb6a2a_nohash_0.wav'\\n\",\n",
        "        \"\\n\",\n",
        "        \"sample_ds = preprocess_dataset([str(sample_file)])\\n\",\n",
        "        \"\\n\",\n",
        "        \"for spectrogram, label in sample_ds.batch(1):\\n\",\n",
        "        \"  prediction = model(spectrogram)\\n\",\n",
        "        \"  plt.bar(commands, tf.nn.softmax(prediction[0]))\\n\",\n",
        "        \"  plt.title(f'Predictions for \\\"{commands[label[0]]}\\\"')\\n\",\n",
        "        \"  plt.show()\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"370QW0-CnVW1\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    }\n",
        "  ]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}